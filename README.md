# ğŸ” Ollama Web Search v2.0

A powerful, intelligent web search tool that combines real-time web search with AI-powered summarization using Ollama and SearXNG. Now featuring advanced caching, parallel processing, multiple output formats, comprehensive error handling, and enterprise-ready deployment options.

## âœ¨ New in v2.0

### ğŸš€ Performance & Reliability
- **âš¡ Parallel Processing**: Fetch multiple URLs simultaneously for 3-5x faster results
- **ğŸ’¾ Intelligent Caching**: Smart caching system reduces redundant requests and improves speed
- **ğŸ”„ Model Fallback**: Automatic fallback between multiple AI models for maximum reliability
- **ğŸ“Š Performance Metrics**: Detailed timing and performance analytics
- **ğŸ›¡ï¸ Enhanced Error Handling**: Comprehensive error handling with graceful degradation

### ğŸ“¤ Output & Integration
- **ğŸ“„ Multiple Output Formats**: JSON, Markdown, HTML, and plain text export
- **ğŸ”§ Advanced CLI**: Feature-rich command-line interface with interactive mode
- **âš™ï¸ Configuration System**: Flexible configuration via files and environment variables
- **ğŸ“ˆ Usage Analytics**: Track performance, cache hits, and system metrics

### ğŸ³ Deployment & DevOps
- **ğŸ³ Docker Compose**: Complete containerized setup with GPU support
- **ğŸ§ª Comprehensive Testing**: Unit tests, integration tests, and performance benchmarks
- **ğŸ“‹ Setup Automation**: One-command setup script for quick deployment
- **ğŸŒ Web Interface Ready**: Optional web UI components for browser access

### ğŸ” Search & AI Enhancements
- **ğŸ¯ Smart URL Filtering**: Intelligent filtering of social media, PDFs, and low-quality content
- **ğŸ¤– Enhanced AI Prompting**: Structured prompts for better, more consistent responses
- **ğŸ” Advanced Search Options**: Configurable search engines, time ranges, and content filters
- **ğŸ“ Source Attribution**: Detailed source metadata with fetch times and content analysis

## ğŸš€ Quick Start

### ğŸ¯ One-Command Setup (Recommended)

```bash
git clone https://github.com/yourusername/ollama_websearch.git
cd ollama_websearch
./setup.sh
```

The setup script will:
- âœ… Check prerequisites (Deno, Docker)
- ğŸ³ Start SearXNG and Ollama containers
- ğŸ“¦ Install default AI models
- âš™ï¸ Configure environment
- ğŸ§ª Run basic functionality test

### ğŸ”§ Manual Installation

#### Prerequisites

1. **Deno Runtime**: Install from [deno.land](https://deno.land/)
2. **Docker & Docker Compose**: For containerized services
3. **Optional**: Ollama installed locally (alternative to Docker)

#### Step-by-Step Setup

1. **Clone and setup**:
   ```bash
   git clone https://github.com/yourusername/ollama_websearch.git
   cd ollama_websearch
   cp .env.example .env  # Customize settings
   ```

2. **Start services**:
   ```bash
   # With GPU support
   COMPOSE_PROFILES=gpu docker-compose up -d
   
   # CPU only
   COMPOSE_PROFILES=cpu docker-compose up -d
   
   # With caching and web interface
   COMPOSE_PROFILES=cpu,cache,web docker-compose up -d
   ```

3. **Install AI models**:
   ```bash
   docker exec ollama-websearch-ollama-cpu ollama pull llama3.2:1b
   docker exec ollama-websearch-ollama-cpu ollama pull llama3.2:3b
   ```

## ğŸ’» Usage

### ğŸ” Basic Search
```bash
# Simple search
./search.sh "your search query here"

# Using Deno tasks
deno task search "latest AI developments"

# Advanced CLI with options
deno run --allow-all cli.ts -m "llama3.2:3b" -r 10 "climate change research"
```

### ğŸ›ï¸ Advanced CLI Options
```bash
# Interactive mode with guided prompts
deno run --allow-all cli.ts --interactive

# Save results to different formats
deno run --allow-all cli.ts -s results.json "AI trends"     # JSON
deno run --allow-all cli.ts -s report.md "AI trends"       # Markdown
deno run --allow-all cli.ts -s report.html "AI trends"     # HTML

# Verbose output with custom model
deno run --allow-all cli.ts -v -m "llama3.1:8b" "space exploration"

# Use specific configuration
deno run --allow-all cli.ts --config custom.json "query"
```

### ğŸ“Š Output Examples

#### Example Output
```
ğŸ” Ollama Web Search - AI-Powered Research Assistant
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ Query: President Mahama grant Amnesty for 999 prisons
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸŒ Fetching: https://www.facebook.com/joy997fm/posts/president-mahama-grants-amnesty-to-998-prisoners...
ğŸŒ Fetching: https://isd.gov.gh/president-mahama-grants-amnesty-to-998-prisoners/
ğŸŒ Fetching: https://resolve.cambridge.org/core/services/aop-cambridge-core/content/view...

ğŸ¤– AI Analysis & Summary:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
President Mahama granted amnesty to 998 prisoners out of 1,014 recommended by the Prisons Service Council. The amnesty affects prisoners across seven categories, with first-time offenders making up the largest group at 787 individuals...
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ¨ Search completed successfully!
```

## ğŸ› ï¸ Configuration

### Environment Variables

The application uses the following environment variables:

- `SEARCH_URL`: SearXNG instance URL (default: `http://localhost:9999/search`)

### Customization

#### Change the AI Model
Edit `main.ts` and modify the model parameter:
```typescript
const result = await ollama.generate({
    model: "llama3.2:3b", // Change to your preferred model
    // ...
});
```

#### Adjust Number of Search Results
Modify the slice parameter in `getNewsUrls()`:
```typescript
.slice(0, 5); // Change from 3 to 5 for more results
```

## ğŸ“ Project Structure

```
ollama_websearch/
â”œâ”€â”€ main.ts          # Main application logic
â”œâ”€â”€ search.sh        # Shell script wrapper
â”œâ”€â”€ deno.json        # Deno configuration
â”œâ”€â”€ deno.lock        # Dependency lock file
â”œâ”€â”€ README.md        # This file
â”œâ”€â”€ LICENSE          # MIT License
â””â”€â”€ .gitignore       # Git ignore rules
```

## ğŸ§© How It Works

1. **ğŸ” Search Query**: The application sends your query to SearXNG with beautiful branding
2. **ğŸŒ URL Extraction**: Extracts top search result URLs with progress indicators
3. **ğŸ“„ Content Fetching**: Downloads webpage content using browser-like headers to avoid blocking
4. **ğŸ§¹ Text Cleaning**: Uses Mozilla Readability algorithm for clean, readable text extraction
5. **ğŸ¤– AI Analysis**: Sends cleaned content to Ollama with enhanced prompting for structured output
6. **âœ¨ Streaming Response**: Returns beautifully formatted AI-generated summary in real-time
7. **ğŸ¨ Professional Output**: Displays results with clear visual hierarchy and source attribution

## ğŸ³ Docker Setup (Alternative)

If you prefer using Docker for the entire setup:

```bash
# Start SearXNG
docker run -d --name searxng -p 9999:8080 searxng/searxng:latest

# Run Ollama in Docker (if not installed locally)
docker run -d --name ollama -p 11434:11434 ollama/ollama
docker exec -it ollama ollama pull llama3.2:1b
```

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Commit your changes**: `git commit -m 'Add amazing feature'`
4. **Push to the branch**: `git push origin feature/amazing-feature`
5. **Open a Pull Request**

### Development Setup

```bash
# Clone your fork
git clone https://github.com/yourusername/ollama_websearch.git
cd ollama_websearch

# Install dependencies (handled by Deno automatically)
deno run --allow-net --allow-env main.ts "test query"
```

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸš€ Recent Improvements

### Version 2.0 Features:
- **ğŸ¨ Beautiful Interface**: Complete visual overhaul with professional branding
- **ğŸ”’ Enhanced Security**: Proper SSL certificate handling without security warnings
- **ğŸŒ Better Compatibility**: Browser-like headers to avoid bot detection
- **ğŸ“ Comprehensive Documentation**: Detailed code comments and JSDoc documentation
- **âš¡ Improved Error Handling**: Graceful degradation with informative error messages
- **âœ¨ Visual Feedback**: Real-time progress indicators and status updates

## ğŸ™ Acknowledgments

- **Matt Williams** ([@technovangelist](https://github.com/technovangelist)) - Former Ollama team member who inspired this project
- **Ollama Team** - For the excellent local AI runtime
- **SearXNG Project** - For privacy-focused search capabilities
- **Mozilla Readability** - For clean content extraction
- **@eliaspereirah** - For suggesting Mozilla Readability approach

## ğŸ¨ Visual Interface

The tool features a beautiful, professional interface with:

- **ğŸ” Branded Header**: Clear project identification and purpose
- **ğŸ“ Query Display**: Elegant query presentation with visual separators
- **ğŸŒ Progress Indicators**: Real-time fetching progress with emojis
- **ğŸ“° Source Attribution**: Clear source identification with visual separators
- **ğŸ¤– AI Section**: Distinct AI analysis section with proper formatting
- **âœ¨ Completion Confirmation**: Professional completion indicator
- **âš ï¸ Error Handling**: Graceful error messages with appropriate icons

## ğŸ“Š System Requirements

- **OS**: Linux, macOS, Windows
- **RAM**: 4GB minimum (8GB+ recommended for larger models)
- **Storage**: 2GB for base model
- **Network**: Internet connection for web search

## ğŸ”§ Troubleshooting

### Common Issues

1. **ğŸ”’ SSL Certificate Issues**: The application now handles SSL certificates properly with robust error handling
2. **ğŸ¤– Model Not Found**: Run `ollama pull llama3.2:1b` to install the required model
3. **ğŸ³ SearXNG Not Running**: Ensure Docker container is running on port 9999
4. **ğŸ” Permission Denied**: Run `chmod +x search.sh` to make the script executable
5. **ğŸŒ Network Errors**: The tool gracefully handles network issues and continues with available sources
6. **ğŸš« Bot Detection**: Browser-like headers are included to avoid being blocked by websites

### Getting Help

- **Issues**: [GitHub Issues](https://github.com/yourusername/ollama_websearch/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/ollama_websearch/discussions)

---

## ğŸŒŸ Why Choose Ollama Web Search?

- **ğŸš€ Fast & Efficient**: Lightweight design with streaming responses
- **ğŸ”’ Privacy-Focused**: Uses SearXNG for private search without tracking
- **ğŸ¨ Beautiful Interface**: Professional, branded terminal experience
- **ğŸ›¡ï¸ Secure**: Proper security practices without bypassing safety measures
- **ğŸ“š Educational**: Well-documented code perfect for learning
- **ğŸŒ Open Source**: MIT licensed, free for everyone to use and contribute

**Experience the future of AI-powered web search! ğŸš€âœ¨**

